{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bbe48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "590e9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load the DVF dataset with proper settings for mixed types.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94c0970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FILTERING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def filter_by_transaction_type(df):\n",
    "    \"\"\"Keep only regular sales transactions.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FILTERING BY TRANSACTION TYPE\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(\"Transaction types available:\")\n",
    "    print(df.groupby('nature_mutation').size())\n",
    "    \n",
    "    df_sales = df[df['nature_mutation'] == 'Vente'].copy()\n",
    "    print(f\"After sales filter: {df_sales.shape[0]} rows\")\n",
    "    \n",
    "    return df_sales\n",
    "\n",
    "def filter_apartments_only(df):\n",
    "    \"\"\"Keep only apartments.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FILTERING FOR APARTMENTS ONLY\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(\"Property types available:\")\n",
    "    print(df.groupby('type_local').size())\n",
    "    \n",
    "    df_apartments = df[df['type_local'] == 'Appartement'].copy()\n",
    "    print(f\"After apartments filter: {df_apartments.shape[0]} rows\")\n",
    "    \n",
    "    return df_apartments\n",
    "\n",
    "def select_key_columns(df):\n",
    "    \"\"\"Select only the essential columns for modeling based on EDA conclusions.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"SELECTING KEY COLUMNS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Based on our EDA conclusions - 8 features + target\n",
    "    key_columns = [\n",
    "        'date_mutation',\n",
    "        'valeur_fonciere', \n",
    "        'code_postal',\n",
    "        'surface_reelle_bati',\n",
    "        'nombre_pieces_principales',\n",
    "        'longitude',\n",
    "        'latitude',\n",
    "        'nombre_lots',\n",
    "        'lot1_surface_carrez',\n",
    "        'lot2_surface_carrez', \n",
    "        'lot3_surface_carrez',\n",
    "        'lot4_surface_carrez',\n",
    "        'lot5_surface_carrez'\n",
    "    ]\n",
    "    \n",
    "    df_selected = df[key_columns].copy()\n",
    "    print(f\"Selected {len(key_columns)} key columns\")\n",
    "    \n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6712cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "def remove_missing_values(df):\n",
    "    \"\"\"Remove rows with missing values in key columns.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"REMOVING MISSING VALUES\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # Check missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(\"Missing values found:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "        \n",
    "        df_clean = df.dropna()\n",
    "        final_count = len(df_clean)\n",
    "        removed_count = initial_count - final_count\n",
    "        \n",
    "        print(f\"Rows removed: {removed_count} ({removed_count/initial_count:.1%})\")\n",
    "        print(f\"Final dataset: {final_count} rows\")\n",
    "        \n",
    "        return df_clean\n",
    "    else:\n",
    "        print(\"No missing values found\")\n",
    "        return df\n",
    "\n",
    "def create_lots_features(df):\n",
    "    \"\"\"Create lot-related features based on EDA conclusions.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"CREATING LOTS FEATURES\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Number of lots with surface data\n",
    "    lot_columns = ['lot1_surface_carrez', 'lot2_surface_carrez', 'lot3_surface_carrez', \n",
    "                   'lot4_surface_carrez', 'lot5_surface_carrez']\n",
    "    \n",
    "    df['nb_lots_surface'] = df[lot_columns].notna().sum(axis=1)\n",
    "    df['a_plusieurs_lots'] = (df['nb_lots_surface'] > 1).astype(int)\n",
    "    \n",
    "    # Drop individual lot surface columns (unreliable as per EDA)\n",
    "    df = df.drop(lot_columns, axis=1)\n",
    "    \n",
    "    print(\"Created features:\")\n",
    "    print(\"- nb_lots_surface: Number of lots with surface data\")\n",
    "    print(\"- a_plusieurs_lots: Binary indicator for multiple lots\")\n",
    "    print(\"- Dropped individual lot surface columns (unreliable)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_surface_outliers(df):\n",
    "    \"\"\"Filter surface outliers based on EDA conclusions: 15-200m².\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FILTERING SURFACE OUTLIERS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    surface_min = 15  # Based on EDA conclusions\n",
    "    surface_max = 200\n",
    "    \n",
    "    print(f\"Surface before filtering:\")\n",
    "    print(f\"Min: {df['surface_reelle_bati'].min():.1f}m², Max: {df['surface_reelle_bati'].max():.1f}m²\")\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    df_filtered = df[\n",
    "        (df['surface_reelle_bati'] >= surface_min) & \n",
    "        (df['surface_reelle_bati'] <= surface_max)\n",
    "    ].copy()\n",
    "    \n",
    "    removed = initial_count - len(df_filtered)\n",
    "    print(f\"Surface filter ({surface_min}-{surface_max}m²): {initial_count} -> {len(df_filtered)} rows\")\n",
    "    print(f\"Removed {removed} outliers ({removed/initial_count:.1%})\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def filter_pieces_outliers(df):\n",
    "    \"\"\"Filter number of pieces outliers based on EDA conclusions: 1-5 pieces.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FILTERING PIECES OUTLIERS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    pieces_min = 1  # Based on EDA conclusions\n",
    "    pieces_max = 5\n",
    "    \n",
    "    print(f\"Pieces before filtering:\")\n",
    "    print(df['nombre_pieces_principales'].value_counts().sort_index())\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    df_filtered = df[\n",
    "        (df['nombre_pieces_principales'] >= pieces_min) & \n",
    "        (df['nombre_pieces_principales'] <= pieces_max)\n",
    "    ].copy()\n",
    "    \n",
    "    removed = initial_count - len(df_filtered)\n",
    "    print(f\"Pieces filter ({pieces_min}-{pieces_max}): {initial_count} -> {len(df_filtered)} rows\")\n",
    "    print(f\"Removed {removed} outliers ({removed/initial_count:.1%})\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def create_target_variable(df):\n",
    "    \"\"\"Create the price per square meter target variable.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"CREATING TARGET VARIABLE (PRIX_M2)\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Calculate price per m2\n",
    "    df['prix_m2'] = df['valeur_fonciere'] / df['surface_reelle_bati']\n",
    "    \n",
    "    # Remove infinite and zero values\n",
    "    df = df[df['prix_m2'] != np.inf]\n",
    "    df = df[df['prix_m2'] > 0]\n",
    "    \n",
    "    print(f\"Prix_m2 statistics:\")\n",
    "    print(df['prix_m2'].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_prix_outliers(df):\n",
    "    \"\"\"Filter price outliers based on EDA conclusions: 4000-20000€/m².\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FILTERING PRIX_M2 OUTLIERS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    prix_min = 4000  # Based on EDA conclusions\n",
    "    prix_max = 20000\n",
    "    \n",
    "    print(f\"Prix_m2 before filtering:\")\n",
    "    print(f\"Min: {df['prix_m2'].min():.0f}€/m², Max: {df['prix_m2'].max():.0f}€/m²\")\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    df_filtered = df[\n",
    "        (df['prix_m2'] >= prix_min) & \n",
    "        (df['prix_m2'] <= prix_max)\n",
    "    ].copy()\n",
    "    \n",
    "    removed = initial_count - len(df_filtered)\n",
    "    print(f\"Prix filter ({prix_min}-{prix_max}€/m²): {initial_count} -> {len(df_filtered)} rows\")\n",
    "    print(f\"Removed {removed} outliers ({removed/initial_count:.1%})\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def extract_time_features(df):\n",
    "    \"\"\"Extract time-based features from date_mutation (keeping only year based on EDA).\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"EXTRACTING TIME FEATURES\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Convert to datetime\n",
    "    df['date_mutation'] = pd.to_datetime(df['date_mutation'])\n",
    "    \n",
    "    # Extract only year (jour, mois had low correlation based on EDA)\n",
    "    df['annee'] = df['date_mutation'].dt.year\n",
    "    \n",
    "    # Drop the date column\n",
    "    df = df.drop('date_mutation', axis=1)\n",
    "    \n",
    "    print(\"Time features created: annee only (jour, mois had low correlation)\")\n",
    "    print(f\"Years in dataset: {sorted(df['annee'].unique())}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_postal_codes(df):\n",
    "    \"\"\"Process postal codes to extract arrondissement.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"PROCESSING POSTAL CODES\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(f\"Postal codes before processing:\")\n",
    "    print(f\"Min: {df['code_postal'].min()}, Max: {df['code_postal'].max()}\")\n",
    "    print(f\"Unique values: {sorted(df['code_postal'].unique())}\")\n",
    "    \n",
    "    # Filter for valid Paris postal codes only (75001-75020)\n",
    "    df = df[(df['code_postal'] >= 75001) & (df['code_postal'] <= 75020)].copy()\n",
    "    print(f\"After filtering valid Paris postal codes: {len(df)} rows\")\n",
    "    \n",
    "    # Extract arrondissement from postal code\n",
    "    df['arrondissement'] = df['code_postal'].astype(int) - 75000\n",
    "    \n",
    "    # Double check arrondissement values are valid (1-20)\n",
    "    invalid_arrond = df[(df['arrondissement'] < 1) | (df['arrondissement'] > 20)]\n",
    "    if len(invalid_arrond) > 0:\n",
    "        print(f\"WARNING: Found {len(invalid_arrond)} invalid arrondissements\")\n",
    "        print(invalid_arrond['arrondissement'].unique())\n",
    "        # Remove invalid arrondissements\n",
    "        df = df[(df['arrondissement'] >= 1) & (df['arrondissement'] <= 20)].copy()\n",
    "    \n",
    "    # Drop old postal code column\n",
    "    df = df.drop('code_postal', axis=1)\n",
    "    \n",
    "    print(\"Arrondissement feature created\")\n",
    "    print(\"Arrondissements distribution:\")\n",
    "    print(df['arrondissement'].value_counts().sort_index())\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4a2f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN CLEANING PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "def clean_data_pipeline(df):\n",
    "    \"\"\"Complete data cleaning pipeline based on EDA conclusions.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PARIS REAL ESTATE DATA CLEANING PIPELINE\")\n",
    "    print(\"BASED ON EDA CONCLUSIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Filter for sales only\n",
    "    df = filter_by_transaction_type(df)\n",
    "    \n",
    "    # 2. Keep apartments only\n",
    "    df = filter_apartments_only(df)\n",
    "    \n",
    "    # 3. Select key columns\n",
    "    df = select_key_columns(df)\n",
    "    \n",
    "    # 4. Create lots features (before removing missing values)\n",
    "    df = create_lots_features(df)\n",
    "    \n",
    "    # 5. Remove missing values (after lots processing)\n",
    "    df = remove_missing_values(df)\n",
    "    \n",
    "    # 6. Filter surface outliers (15-200m²)\n",
    "    df = filter_surface_outliers(df)\n",
    "    \n",
    "    # 7. Filter pieces outliers (1-5 pieces)\n",
    "    df = filter_pieces_outliers(df)\n",
    "    \n",
    "    # 8. Create target variable\n",
    "    df = create_target_variable(df)\n",
    "    \n",
    "    # 9. Filter price outliers (4000-20000€/m²)\n",
    "    df = filter_prix_outliers(df)\n",
    "    \n",
    "    # 10. Extract time features (year only)\n",
    "    df = extract_time_features(df)\n",
    "    \n",
    "    # 11. Process postal codes (create arrondissement)\n",
    "    df = process_postal_codes(df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CLEANING COMPLETE - READY FOR MODELING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Final dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(\"\\nFinal features:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5aeb20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "Dataset loaded: 414451 rows, 40 columns\n",
      "\n",
      "============================================================\n",
      "PARIS REAL ESTATE DATA CLEANING PIPELINE\n",
      "BASED ON EDA CONCLUSIONS\n",
      "============================================================\n",
      "\n",
      "========================================\n",
      "FILTERING BY TRANSACTION TYPE\n",
      "========================================\n",
      "Transaction types available:\n",
      "nature_mutation\n",
      "Adjudication                             886\n",
      "Echange                                 3089\n",
      "Expropriation                             19\n",
      "Vente                                 406010\n",
      "Vente en l'état futur d'achèvement      4354\n",
      "Vente terrain à bâtir                     93\n",
      "dtype: int64\n",
      "After sales filter: 406010 rows\n",
      "\n",
      "========================================\n",
      "FILTERING FOR APARTMENTS ONLY\n",
      "========================================\n",
      "Property types available:\n",
      "type_local\n",
      "Appartement                                 196255\n",
      "Dépendance                                  176663\n",
      "Local industriel. commercial ou assimilé     28241\n",
      "Maison                                        2569\n",
      "dtype: int64\n",
      "After apartments filter: 196255 rows\n",
      "\n",
      "========================================\n",
      "SELECTING KEY COLUMNS\n",
      "========================================\n",
      "Selected 13 key columns\n",
      "\n",
      "========================================\n",
      "CREATING LOTS FEATURES\n",
      "========================================\n",
      "Created features:\n",
      "- nb_lots_surface: Number of lots with surface data\n",
      "- a_plusieurs_lots: Binary indicator for multiple lots\n",
      "- Dropped individual lot surface columns (unreliable)\n",
      "\n",
      "========================================\n",
      "REMOVING MISSING VALUES\n",
      "========================================\n",
      "Missing values found:\n",
      "valeur_fonciere              1724\n",
      "surface_reelle_bati             4\n",
      "nombre_pieces_principales       4\n",
      "longitude                     467\n",
      "latitude                      467\n",
      "dtype: int64\n",
      "Rows removed: 2195 (1.1%)\n",
      "Final dataset: 194060 rows\n",
      "\n",
      "========================================\n",
      "FILTERING SURFACE OUTLIERS\n",
      "========================================\n",
      "Surface before filtering:\n",
      "Min: 1.0m², Max: 1500.0m²\n",
      "Surface filter (15-200m²): 194060 -> 180979 rows\n",
      "Removed 13081 outliers (6.7%)\n",
      "\n",
      "========================================\n",
      "FILTERING PIECES OUTLIERS\n",
      "========================================\n",
      "Pieces before filtering:\n",
      "nombre_pieces_principales\n",
      "0.0       170\n",
      "1.0     42243\n",
      "2.0     65965\n",
      "3.0     42295\n",
      "4.0     19463\n",
      "5.0      7943\n",
      "6.0      2287\n",
      "7.0       495\n",
      "8.0        79\n",
      "9.0        15\n",
      "10.0        8\n",
      "11.0        4\n",
      "12.0        2\n",
      "13.0        2\n",
      "15.0        1\n",
      "17.0        2\n",
      "18.0        1\n",
      "21.0        1\n",
      "22.0        1\n",
      "32.0        1\n",
      "34.0        1\n",
      "Name: count, dtype: int64\n",
      "Pieces filter (1-5): 180979 -> 177909 rows\n",
      "Removed 3070 outliers (1.7%)\n",
      "\n",
      "========================================\n",
      "CREATING TARGET VARIABLE (PRIX_M2)\n",
      "========================================\n",
      "Prix_m2 statistics:\n",
      "count    1.779090e+05\n",
      "mean     4.181726e+04\n",
      "std      2.319889e+05\n",
      "min      3.750000e-03\n",
      "25%      8.666667e+03\n",
      "50%      1.067333e+04\n",
      "75%      1.330303e+04\n",
      "max      2.755501e+07\n",
      "Name: prix_m2, dtype: float64\n",
      "\n",
      "========================================\n",
      "FILTERING PRIX_M2 OUTLIERS\n",
      "========================================\n",
      "Prix_m2 before filtering:\n",
      "Min: 0€/m², Max: 27555014€/m²\n",
      "Prix filter (4000-20000€/m²): 177909 -> 140318 rows\n",
      "Removed 37591 outliers (21.1%)\n",
      "\n",
      "========================================\n",
      "EXTRACTING TIME FEATURES\n",
      "========================================\n",
      "Time features created: annee only (jour, mois had low correlation)\n",
      "Years in dataset: [2020, 2021, 2022, 2023, 2024]\n",
      "\n",
      "========================================\n",
      "PROCESSING POSTAL CODES\n",
      "========================================\n",
      "Postal codes before processing:\n",
      "Min: 75001.0, Max: 76000.0\n",
      "Unique values: [75001.0, 75002.0, 75003.0, 75004.0, 75005.0, 75006.0, 75007.0, 75008.0, 75009.0, 75010.0, 75011.0, 75012.0, 75013.0, 75014.0, 75015.0, 75016.0, 75017.0, 75018.0, 75019.0, 75020.0, 76000.0]\n",
      "After filtering valid Paris postal codes: 137917 rows\n",
      "Arrondissement feature created\n",
      "Arrondissements distribution:\n",
      "arrondissement\n",
      "1      1309\n",
      "2      2016\n",
      "3      2907\n",
      "4      2181\n",
      "5      3787\n",
      "6      2920\n",
      "7      3395\n",
      "8      2485\n",
      "9      5105\n",
      "10     7250\n",
      "11    11754\n",
      "12     8070\n",
      "13     7039\n",
      "14     7306\n",
      "15    15127\n",
      "16    10749\n",
      "17    11894\n",
      "18    14985\n",
      "19     8165\n",
      "20     9473\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "CLEANING COMPLETE - READY FOR MODELING\n",
      "============================================================\n",
      "Final dataset: 137917 rows, 11 columns\n",
      "\n",
      "Final features:\n",
      "- valeur_fonciere\n",
      "- surface_reelle_bati\n",
      "- nombre_pieces_principales\n",
      "- longitude\n",
      "- latitude\n",
      "- nombre_lots\n",
      "- nb_lots_surface\n",
      "- a_plusieurs_lots\n",
      "- prix_m2\n",
      "- annee\n",
      "- arrondissement\n",
      "\n",
      "✅ Model-ready dataset saved: model_paris_20_24.csv\n",
      "Final shape: (137917, 11)\n"
     ]
    }
   ],
   "source": [
    "df = load_data(\"full_paris_20_24.csv\")\n",
    "df_clean = clean_data_pipeline(df)\n",
    "# Save model-ready dataset\n",
    "output_file = \"model_paris_20_24.csv\"\n",
    "df_clean.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ Model-ready dataset saved: {output_file}\")\n",
    "print(f\"Final shape: {df_clean.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
